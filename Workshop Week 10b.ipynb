{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes' theorem with the \"naive\" assumption of conditional independence between every pair of features given the value of the class variable. Bayes'theorem states the following relationship, given class variable $y$ and dependent feature vector $x_1$ through $x_n$,:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}\n",
    "                                 {P(x_1, \\dots, x_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the naive conditional independence assumption, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use Maximum A Posteriori (MAP) estimation to estimate $P(y)$ and $P(x_i \\mid y)$; the former is then the relative frequency of class $y$ in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*:\n",
    "H. Zhang (2004). The optimality of Naive Bayes. Proc. FLAIRS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB implements the Gaussian Naive Bayes algorithm for classification.   \n",
    "The likelihood of the features is assumed to be Gaussian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\sigma_y$ and $\\mu_y$  are estimated using maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** - The training data is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Training a GaussianNB model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb= GaussianNB()\n",
    "gnb.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**: Predict the label of a data [-0.8,-1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test =np.array([[-0.8,-1]])\n",
    "gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test =np.array([[-2,-7]])\n",
    "gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*   \n",
    "C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** - The training data is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4, 0, 2, 1, 4, 2, 4, 4, 1, 1, 0, 1, 0, 4, 3, 2, 0, 4, 1, 4, 3,\n",
       "        0, 2, 1, 2, 3, 1, 4, 4, 2, 4, 4, 4, 3, 0, 0, 3, 0, 4, 1, 2, 1, 3,\n",
       "        2, 4, 4, 3, 4, 3, 1, 3, 2, 1, 3, 1, 0, 0, 3, 2, 3, 2, 2, 4, 1, 0,\n",
       "        0, 2, 2, 1, 2, 1, 3, 2, 3, 4, 1, 3, 3, 4, 1, 3, 2, 4, 1, 0, 2, 1,\n",
       "        1, 1, 2, 4, 3, 2, 1, 1, 3, 3, 0, 3],\n",
       "       [2, 3, 1, 0, 0, 1, 4, 4, 3, 2, 1, 3, 1, 3, 3, 1, 1, 0, 0, 2, 2, 2,\n",
       "        4, 3, 4, 0, 2, 0, 0, 2, 3, 2, 3, 0, 0, 0, 3, 2, 4, 3, 4, 2, 3, 1,\n",
       "        0, 3, 0, 4, 1, 3, 3, 0, 2, 3, 0, 4, 2, 1, 1, 0, 3, 0, 0, 4, 0, 4,\n",
       "        0, 2, 4, 4, 3, 4, 1, 1, 0, 2, 3, 2, 3, 1, 4, 4, 0, 4, 0, 0, 4, 0,\n",
       "        0, 0, 3, 1, 2, 0, 0, 4, 1, 4, 0, 3],\n",
       "       [4, 2, 4, 1, 2, 2, 0, 0, 1, 1, 2, 0, 4, 4, 0, 3, 3, 3, 0, 0, 4, 4,\n",
       "        1, 1, 0, 2, 1, 4, 3, 0, 3, 4, 0, 0, 1, 4, 4, 2, 0, 1, 3, 4, 3, 3,\n",
       "        4, 4, 2, 0, 1, 2, 0, 0, 0, 1, 3, 0, 4, 4, 3, 4, 0, 2, 1, 4, 1, 4,\n",
       "        4, 0, 0, 3, 2, 3, 1, 2, 1, 3, 4, 3, 0, 0, 4, 4, 1, 3, 4, 4, 4, 2,\n",
       "        1, 3, 0, 2, 2, 0, 1, 4, 1, 4, 0, 0],\n",
       "       [2, 3, 3, 1, 4, 3, 4, 0, 0, 3, 1, 0, 4, 2, 4, 3, 0, 0, 2, 4, 1, 0,\n",
       "        1, 4, 2, 3, 1, 4, 2, 4, 0, 2, 3, 3, 1, 1, 2, 1, 2, 1, 2, 3, 1, 0,\n",
       "        1, 4, 0, 4, 2, 1, 2, 0, 4, 2, 4, 0, 1, 1, 0, 2, 4, 4, 1, 2, 0, 1,\n",
       "        2, 4, 1, 1, 0, 4, 3, 0, 0, 3, 4, 4, 1, 4, 3, 0, 1, 2, 3, 1, 2, 3,\n",
       "        3, 1, 2, 1, 2, 2, 1, 2, 2, 4, 4, 1],\n",
       "       [4, 0, 1, 1, 4, 2, 3, 0, 1, 2, 3, 3, 4, 0, 3, 2, 4, 2, 2, 2, 3, 4,\n",
       "        3, 4, 1, 0, 2, 0, 1, 1, 0, 0, 3, 1, 4, 2, 0, 0, 3, 3, 1, 1, 0, 1,\n",
       "        3, 4, 3, 4, 4, 1, 2, 2, 3, 3, 1, 1, 4, 2, 0, 3, 2, 1, 0, 1, 4, 3,\n",
       "        2, 4, 1, 4, 1, 2, 3, 4, 4, 2, 0, 2, 0, 1, 2, 4, 2, 2, 4, 3, 2, 1,\n",
       "        1, 3, 1, 3, 1, 3, 4, 4, 3, 3, 1, 1],\n",
       "       [3, 0, 1, 3, 1, 2, 4, 4, 3, 4, 0, 4, 2, 4, 4, 1, 4, 3, 1, 4, 2, 4,\n",
       "        1, 1, 0, 4, 1, 3, 0, 2, 0, 4, 3, 1, 0, 1, 0, 3, 1, 2, 1, 4, 2, 3,\n",
       "        1, 2, 4, 4, 0, 0, 0, 4, 4, 4, 3, 1, 0, 3, 0, 0, 4, 2, 2, 0, 4, 2,\n",
       "        1, 0, 2, 0, 4, 0, 1, 2, 4, 0, 3, 0, 0, 3, 4, 1, 2, 2, 1, 1, 2, 4,\n",
       "        1, 0, 4, 1, 4, 1, 1, 3, 0, 3, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**: Training a MultinomialNB model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**: Predict the label of a data X[2:3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X[2:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Process on 'Iris' Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have studied how to use KNN algorithm to do classification task on 'iris' data. Here,we are going to employ the GaussianNB to conduct the same task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_dataset = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**ï¼šReport the acuracy result on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score ,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb= GaussianNB()\n",
    "gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  1.0\n"
     ]
    }
   ],
   "source": [
    "y_test_pred= gnb.predict(X_test)\n",
    "print(\"Accuracy \",accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "y_test_pred= mnb.predict(X_test)\n",
    "print(\"Accuracy \",accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
